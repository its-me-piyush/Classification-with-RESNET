{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/its-me-piyush/Classification-with-RESNET/blob/main/Classification_with_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDxbrRA2Ym-Z"
      },
      "source": [
        "## Types of Resnet \n",
        "- ResNet-18\n",
        "- ResNet-34\n",
        "- ResNet-50 -- Done (accuracy: __.__%)\n",
        "- ResNet-101\n",
        "- ResNet-152\n",
        "- ResNet-164\n",
        "- ResNet-1202"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdXgHRXoGNlr"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "\\begin{align}\n",
        "         THEORY\n",
        "    \\end{align}\n",
        "Lets say,\n",
        "\n",
        "\\begin{align}\n",
        "    imagesize = 300, 300, 3\n",
        "    \\end{align}\n",
        "And the architecture of resnet50 is:\n",
        "\n",
        "<!-- ![Resnet 50 Architecture](https://cdn-5f733ed3c1ac190fbc56ef88.closte.com/wp-content/uploads/2019/07/ResNet50_architecture-1.png) or -->\n",
        "\n",
        "![Resnet50 Architecture](https://miro.medium.com/max/1400/0*9LqUp7XyEx1QNc6A.png)\n",
        "\n",
        "---\n",
        "\n",
        "The **FIRST LAYER** of on the resnet:\n",
        "```\n",
        "convolution + batch normalization + max pooling where,\n",
        "filter size = 7 * 7, and 64 such filters\n",
        "stride = 2\n",
        "padding = 3 \n",
        "```\n",
        "---\n",
        "The Formula for calculating the shape of output\n",
        "\n",
        "\\begin{align}\n",
        "        \\frac{n + 2P - f}{s} +1 * \\frac{n + 2P - f}{s} +1 * {outputchannel} \n",
        "    \\end{align}\n",
        "\n",
        "---\n",
        "\n",
        "**EXAMPLE**\n",
        "```\n",
        "imagesize = 300, 300, 3\n",
        "\n",
        "n = 300\n",
        "f = 7\n",
        "P = 3\n",
        "outputchaannel = 64\n",
        "stride = 2\n",
        "``` \n",
        "\\begin{align}\n",
        "        \\frac{300 + 2 (3) - 7}{2} +1 * \\frac{300 + 2 (3) - 7}{2} +1 * {outputchannel} \n",
        "    \\end{align}\n",
        "\n",
        "that is:\n",
        "```\n",
        "output size = 150 * 150 * 64 \n",
        "```\n",
        "\n",
        "```\n",
        "## NOTE: Stride 2 means we have to reduce the size of the image without using the pooling layer.\n",
        "```\n",
        "---\n",
        "The next layer is **max pool** layer\n",
        "```\n",
        "n = 150 (output of previous layer)\n",
        "f = 3\n",
        "P = 1 (not given therefore one)\n",
        "outputchannel = 64 (not given then same as previous)\n",
        "stride = 2\n",
        "```\n",
        "\\begin{align}\n",
        "        \\frac{150 + 2(1) - 3}{2} +1 * \\frac{150 + 2(1) - 3}{2} +1 * {output channel} \n",
        "    \\end{align}\n",
        "\n",
        "that is:\n",
        "```\n",
        "output size = 75 * 75 * 64\n",
        "```\n",
        "and so on...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GggIlt3bSsi8"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "\\begin{align}\n",
        "        Identity\\ Block\\ (Input\\ size == Output\\ size)\n",
        "    \\end{align}\n",
        "\n",
        "![Both Blocks](https://www.researchgate.net/profile/Antonio-Theophilo/publication/321347448/figure/fig2/AS:565869411815424@1511925189281/Bottleneck-Blocks-for-ResNet-50-left-identity-shortcut-right-projection-shortcut.png)\n",
        "\n",
        "---\n",
        "---\n",
        "\\begin{align}\n",
        "        Convolution\\ Block\\ (Input\\ Size\\ != Output\\ Size)\n",
        "      \\end{align}\n",
        "\n",
        "So what happens is whenever the input size and the output size are the same then we can add the input X directly to the output but if the input size is not equal to the output size then we can not add the input X in the output so thats why we use convolution block to bacially make the input and output sizes same.\n",
        "\n",
        "---\n",
        "Lets say that:\n",
        "```\n",
        "input size = 56, 56, 64\n",
        "and the output size = 28, 28, 128\n",
        "```  \n",
        "\n",
        "There are two options for *matching the output size*,\n",
        "\n",
        "- Padding the input volume\n",
        "- Perform 1*1 convolutions\n",
        "\n",
        "```\n",
        "So. bacially we use the same method we create a convolution block of 1*1 with no padding\n",
        "and strids as 2\n",
        "```\n",
        "\\begin{align}\n",
        "    \\frac{n + 2*P - f}{s} +1 * \\frac{n + 2*P - f}{s}\n",
        "    \\end{align}\n",
        "\n",
        "so,\n",
        "```\n",
        "as input size = 56, 56, 64\n",
        "output size = 28, 28, 128\n",
        "padding = 0 and\n",
        "strides = 2\n",
        "f = 1\n",
        "```\n",
        "\\begin{align}\n",
        "    \\frac{56 + 2*0 - 1}{2} +1 * \\frac{56 + 2*0 - 1}{2}\n",
        "    \\end{align}\n",
        "\n",
        "which will give us 28 * 28 as the output size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5omuf0lsJWV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VGqvVgruhi7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "# device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmMynBoM4RYZ"
      },
      "outputs": [],
      "source": [
        "# Mount G-Drive \n",
        "from google.colab import drive\n",
        "import time\n",
        "\n",
        "def mountGDrive():\n",
        "  print(\"[INFO] Mounting google drive to this notebook.\")\n",
        "  drive.mount('/content/gdrive')\n",
        "  print(\"\\n-------------------------------\\n[DONE] G-Drive Mount Successful\\n-------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9hsHYpXfc9U"
      },
      "outputs": [],
      "source": [
        "# mountGDrive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnLG4k9T43f-"
      },
      "outputs": [],
      "source": [
        "def unzipFiles():\n",
        "  print(\"[INFO] Unzipping the dataset from google drive.\")\n",
        "  %time !unzip -q gdrive/My\\ Drive/Cloud\\ Research__/dataset/data.zip\n",
        "  print(\"-------------------------------\\n[DONE] Unzip Successful\\n-------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk4e2EaS19Lf"
      },
      "outputs": [],
      "source": [
        "# !unzip test1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3Fgcj4n2GRW"
      },
      "outputs": [],
      "source": [
        "def unzipTrainData():\n",
        "  print(f\"[INFO] Unzipping Training Data\")\n",
        "  %time !unzip -q train.zip\n",
        "  print(\"-------------------------------\\n[DONE] Unzipping Training Data Successful\\n-------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAjDMC0YNYZf"
      },
      "outputs": [],
      "source": [
        "# def unzipTestData():\n",
        "#   print(f\"[INFO] Unzipping Testing Data\")\n",
        "#   %time !unzip -q test1.zip\n",
        "#   print(\"-------------------------------\\n[DONE] Unzipping Testing Data Successful\\n-------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHgtNJVSFLzT"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# new = pd.read_csv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reBLd2rV7wz9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# path = 'train'\n",
        "# print(f'Total number of training data: {len(os.listdir(path))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-FqKqEq2qaO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El4SWm2kINMm"
      },
      "outputs": [],
      "source": [
        "def createCommonList(path):\n",
        "  print(\"[INFO] Creating common List\")\n",
        "  commonList = []\n",
        "  %time\n",
        "  for i in os.listdir(path):\n",
        "    commonList.append(i)\n",
        "  print(\"-------------------------------\\n[DONE] Common List creation Successful\\n-------------------------------\")\n",
        "  return commonList\n",
        "# commonList[0] # dog.21.jpg <-- output\n",
        "# commonList[12].split('.')[0] # dog <-- output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuyUAmCnaLNr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def createFinalList(commonList, path):\n",
        "  print(\"[INFO] Creating Final Train List\")\n",
        "  final_train_list = []\n",
        "  %time\n",
        "  for i in commonList:\n",
        "    final_train_list.append((i.split('.')[0], path+'/'+i))\n",
        "  print(f'\\nFirst element: {final_train_list[0]}\\n')\n",
        "  print(\"-------------------------------\\n[DONE] Final Test List Creation Successful\\n-------------------------------\")\n",
        "  return final_train_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7vexbGRlbRo"
      },
      "outputs": [],
      "source": [
        "# Testing spliting data\n",
        "# mountGDrive()\n",
        "# unzipFiles()\n",
        "# unzipTrainData()\n",
        "# commonList = createCommonList('train')\n",
        "# finalList = createFinalList(commonList, 'train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mn05PpBsHMA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itdmupaFlAxh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def splitData(ftl):\n",
        "  train_dog_list = []\n",
        "  train_list = []\n",
        "  train_cat_list = []\n",
        "  i = 0\n",
        "  j = 0\n",
        "  while len(train_dog_list) < 5000:\n",
        "    if ftl[i][0] == 'dog':\n",
        "      train_dog_list.append(('dog', ftl[i][1]))\n",
        "      ftl.remove(ftl[i])\n",
        "      # print(f'len of dog list: {len(train_dog_list)}')\n",
        "    else:\n",
        "      if (len(train_cat_list) != 5000):\n",
        "        train_cat_list.append(('cat', ftl[i][1]))\n",
        "        ftl.remove(ftl[i])\n",
        "      # print(f'len of cat list: {len(train_cat_list)}')\n",
        "    i += 1\n",
        "    \n",
        "  train_list = train_dog_list + train_cat_list\n",
        "  return train_list, ftl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Wh3H8DlrxF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMtOtW-EJJqo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "def createDataFrame(final_train_list):\n",
        "  train_df = pd.DataFrame(final_train_list, columns=['pet_type', 'image'])\n",
        "  train_df.head()\n",
        "  return train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsEa-c0UZIOt"
      },
      "outputs": [],
      "source": [
        "# new = new.drop(172)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tf1bhRlKBt2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "def plotAnyImage(train_df, index):\n",
        "  plt.imshow(mpimg.imread(train_df['image'][index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvpb7JzCKUfl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def generalInfoAboutDAtaFrame(train_df):\n",
        "  print(f'Total numner of images in dataset: {len(train_df)}')\n",
        "  pet_count = train_df['pet_type'].value_counts()\n",
        "  print(f'Pets in Each Category:\\n{pet_count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nmq4R3XUIpS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgaAa4YXa_XL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmqncTjTNUm0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "\n",
        "def imagesAndLabelsFormater(train_df):\n",
        "  labels = []\n",
        "  images = []\n",
        "\n",
        "  im_size = 224\n",
        "\n",
        "  for i in train_df['pet_type']:\n",
        "    labels.append(i)\n",
        "\n",
        "  for i in range(len(train_df)):\n",
        "    # print(i)\n",
        "    print(f'[INFO] Processing image {str(len(images))} of {str(len(train_df))}')\n",
        "    img = cv2.imread(train_df['image'][i])\n",
        "    img2 = cv2.resize(img, (224, 224))\n",
        "    images.append(img2)\n",
        "  print('[DONE] All images uploaded and resized.')\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLnQHMCLNy9i"
      },
      "outputs": [],
      "source": [
        "# labels\n",
        "# print(f'[INFO] Images shape: {images[0].shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BMEE6UzO65x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def convertIntoArray(images):\n",
        "  images = np.array(images)\n",
        "  print(f'[INFO] Processed images shape: {images.shape}')\n",
        "  return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUv_ZrMRFyrd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhs7esTZBzeM"
      },
      "outputs": [],
      "source": [
        "# print('[INFO] D')\n",
        "# imag1 = images[0].astype('float32') / 255.0\n",
        "# imag1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcVNCtAqDNHb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPpMT4ApCs1f"
      },
      "outputs": [],
      "source": [
        "# images[0:13650][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cdWgkBsRYLU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# final_images = []\n",
        "# for i in range(len(images[0:13650])):\n",
        "#   print(i)\n",
        "#   img1 = images[i].astype('float32') / 255.0\n",
        "#   final_images.append(img1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0NWnoWPED5X"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XInYjKfATwrV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for i in range(len(images[13650:])):\n",
        "#   print(i)\n",
        "#   img1 = images[i].astype('float32') / 255.0\n",
        "#   final_images.append(img1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khf8t60s5Lcx"
      },
      "outputs": [],
      "source": [
        "# images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5-MxFYs5MJE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "def custom_data_label_encoder(y_labels):\n",
        "  y = y_labels  # cat, cat, dog, cat, dog...\n",
        "  y_labelEncoder = LabelEncoder()\n",
        "  y = y_labelEncoder.fit_transform(y)  \n",
        "  y = y.reshape(-1, 1)\n",
        "  onehotencorder = ColumnTransformer(\n",
        "    [('one_hot_encoder', OneHotEncoder(), [0])],\n",
        "    remainder='passthrough'                     \n",
        "  )\n",
        "  return onehotencorder.fit_transform(y)\n",
        "\n",
        "# Y = custom_data_label_encoder(train_df['pet_type'].values)\n",
        "# Y[0] # array([1., 0.]) <-- Output\n",
        "# print(f'[INFO] Encoded Label shape: {Y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U49oDpf_4KBu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# from sklearn.utils import shuffle\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# images, Y = shuffle(images, Y, random_state=1)\n",
        "\n",
        "# train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.08, random_state=415)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "supqOPkB4snx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# test_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmZzLbxqERBl"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "# from IPython.display import svg\n",
        "from keras.utils.vis_utils import model_to_dot, plot_model\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy3eUWJJV5s8"
      },
      "outputs": [],
      "source": [
        "class RESNET34():\n",
        "  def identity_layer(self, X, f, filters):\n",
        "    F1, F2 = filters\n",
        "\n",
        "    X_original = X\n",
        "\n",
        "    #first layer\n",
        "    X = Conv2D(filters = F1, kernel_size=(3,3), strides=(1,1), padding='same')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # second layer\n",
        "    X = Conv2D(filters = F2, kernel_size=(1,1), strides=(1,1), padding='same')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Add()([X, X_original])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "  def convolutional_block(self, X, f, filters, s=2):\n",
        "    F1, F2 = filters\n",
        "\n",
        "    X_original = X\n",
        "\n",
        "    #first layer\n",
        "    X = Conv2D(filters = F1, kernel_size=(3,3), strides=(1,1), padding='same')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # second layer\n",
        "    X = Conv2D(filters = F2, kernel_size=(1,1), strides=(1,1), padding='same')(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "\n",
        "    # Shortcut path\n",
        "    X_original = Conv2D(filters=F2, kernel_size=(1, 1), strides=(s, s), padding='same')(X_original)\n",
        "    X_original = BatchNormalization(axis=3)(X_original)\n",
        "\n",
        "    # Final Step is to add the initial input to the output \n",
        "    # function and then perform activation function for the final output\n",
        "    X = Add()([X, X_original])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "    # 34 = 3 4 6 3 ?\n",
        "    # now = 3 4 4 2\n",
        "    # https://www.analyticsvidhya.com/blog/2021/08/how-to-code-your-resnet-from-scratch-in-tensorflow/\n",
        "    \n",
        "\n",
        "  def runResnet34(self, input_shape=(224, 224, 3), classes = 2):\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # ZeroPadding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # X.shape = (230, 230, 3)\n",
        "\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2))(X) # layer 1\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X) # layer 2\n",
        "\n",
        "    #stage 1\n",
        "    X = self.convolutional_block(X, f=3, filters=[64, 64], s=1) # layer 3, 4\n",
        "    X = self.identity_layer(X, f=3, filters=[64, 64]) # layer 5, 6\n",
        "    X = self.identity_layer(X, f=3, filters=[64, 64]) # layer 7, 8\n",
        "\n",
        "    #stage 2\n",
        "    X = self.convolutional_block(X, f=3, filters=[128, 128], s=1) # layer 9, 10\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128]) # layer 11, 12\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128]) # layer 13, 14\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128]) # layer 15, 16\n",
        "\n",
        "    #stage 3\n",
        "    X = self.convolutional_block(X, f=3, filters=[256, 256], s=1) # layer 17, 18\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256]) # layer 19, 20\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256]) # layer 21, 22\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256]) # layer 23, 24\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256]) # layer 25, 26\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256]) # layer 27, 28\n",
        "\n",
        "    #stage 4  \n",
        "\n",
        "    X = self.convolutional_block(X, f=3, filters=[512, 512], s=1) # layer 29, 30\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512]) # layer 31, 32\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512]) # layer 33, 34\n",
        "\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
        "\n",
        "    ################CODE END HERE################\n",
        "\n",
        "    # Output layer\n",
        "    X = Flatten()(X) # 2D or 3D image to 1D vector \n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), \n",
        "              kernel_initializer=glorot_uniform(seed=0))(X) \n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet34')\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMy0R9N95ICl"
      },
      "outputs": [],
      "source": [
        "class RESNET():\n",
        "  def identity_layer(self, X, f, filters):  \n",
        "    F1, F2, F3 = filters # for first layer F1 = 64, F2 = 64, F3 = 256 according to the resnet50 Architecture\n",
        "\n",
        "    X_original = X\n",
        "\n",
        "    # First Layer\n",
        "    X = Conv2D(filters = F1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(X)\n",
        "    # After every convolational layer we perform batch normalization\n",
        "    X = BatchNormalization(axis=3)(X) # axis 3 means we are performing batch normalization on output channels therefore 3 coz its R, G, B\n",
        "    # At the end we perform activation function\n",
        "    X = Activation('relu')(X)\n",
        "    ############################################\n",
        "\n",
        "    # Second Layer\n",
        "    X = Conv2D(filters = F2, kernel_size=(f, f), strides=(1, 1), padding='same')(X)   # f will be 3 according to the Architecture\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    ############################################\n",
        "\n",
        "    # Third Layer\n",
        "    X = Conv2D(filters = F3, kernel_size=(1, 1), strides=(1, 1), padding='valid')(X)   # f will be 3 according to the Architecture\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "    # Final Step is to add the initial input to the output function and then perform activation function for the final output\n",
        "    X = Add()([X, X_original])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "  def convolutional_block(self, X, f, filters, s=2):   \n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_original = X\n",
        "\n",
        "    # First Layer\n",
        "    X = Conv2D(F1, (1, 1), strides=(s, s), padding='valid')(X) # 1,1 is filter size\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    ############################################\n",
        "\n",
        "    # Second Layer\n",
        "    X = Conv2D(filters = F2, kernel_size=(f, f), strides=(1, 1), padding='same')(X)  \n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    ############################################\n",
        "\n",
        "    # Third Layer\n",
        "    X = Conv2D(filters = F3, kernel_size=(1, 1), strides=(1, 1), padding='valid')(X)  \n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "    # Shortcut path\n",
        "    X_original = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid')(X_original)\n",
        "    X_original = BatchNormalization(axis=3)(X_original)\n",
        "\n",
        "    # Final Step is to add the initial input to the output function and then perform activation function for the final output\n",
        "    X = Add()([X, X_original])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "  \n",
        "  def runResnet50(self, input_shape=(224, 224, 3), classes = 2):\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # ZeroPadding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # X.shape = (230, 230, 3)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2))(X) # layer 1\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X) # layer 2\n",
        "    \n",
        "    # X.shape = (55, 55, 64)\n",
        "\n",
        "    # Stage 2\n",
        "    X = self.convolutional_block(X, f=3, filters=[64, 64, 256], s=1) # layer 3, 4, 5 \n",
        "    # X.shape = (55, 55, 256)\n",
        "    X = self.identity_layer(X, f=3, filters=[64, 64, 256]) # layer 6, 7, 8\n",
        "    X = self.identity_layer(X, f=3, filters=[64, 64, 256]) # layer 9, 10, 11\n",
        "    # X.shape = (55, 55, 256)\n",
        "    \n",
        "\n",
        "    # Stage 3\n",
        "    X = self.convolutional_block(X, f=3, filters=[128, 128, 512], s=2) # layer 12, 13, 14\n",
        "    # X.shape = (28, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 15, 16, 17\n",
        "    # X.shape = (28, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 18, 19, 20\n",
        "    # X.shape = (28, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 21, 22, 23\n",
        "    # X.shape = (28, 28, 512)\n",
        "    \n",
        "\n",
        "    # Stage 4\n",
        "    X = self.convolutional_block(X, f=3, filters=[256, 256, 1024], s=2) # layer 24, 25, 26\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 27, 28, 29\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 30, 31, 32\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 33, 34, 35\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 36, 37, 38\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "\n",
        "    # Stage 5\n",
        "    X = self.convolutional_block(X, f=3, filters=[512, 512, 2048], s=2) # layer 42, 43, 44 \n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 45, 46, 47\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 48, 49, 50\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    \n",
        "\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X) \n",
        "    # X.shape = (3, 3, 2048)\n",
        "    # X.shape = (3, 3, 2048)\n",
        "\n",
        "    ################CODE END HERE################\n",
        "\n",
        "    # Output layer\n",
        "    X = Flatten()(X) # 2D or 3D image to 1D vector \n",
        "    # X.shape = (None, 18432)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X) \n",
        "    # X.shape = (None, 2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "  def runResnet101(self, input_shape=(224, 224, 3), classes = 2):\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # ZeroPadding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # X.shape = (230, 230, 3)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2))(X) # layer 1\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X) # layer 2\n",
        "    \n",
        "    # X.shape = (55, 55, 3)\n",
        "\n",
        "    # Stage 2\n",
        "    X = self.convolutional_block(X, f=3, filters=[64, 64, 256], s=1) # layer 3, 4, 5 \n",
        "    # X.shape = (55, 55, 256)\n",
        "    X = self.identity_layer(X, f=3, filters=[64, 64, 256]) # layer 6, 7, 8\n",
        "    X = self.identity_layer(X, f=3, filters=[64, 64, 256]) # layer 9, 10, 11\n",
        "    # X.shape = (55, 55, 256)\n",
        "    \n",
        "\n",
        "    # Stage 3\n",
        "    X = self.convolutional_block(X, f=3, filters=[128, 128, 512], s=2) # layer 12, 13, 14\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 15, 16, 17\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 18, 19, 20\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 21, 22, 23\n",
        "    # X.shape = (25, 28, 512)\n",
        "    \n",
        "\n",
        "    # Stage 4\n",
        "    X = self.convolutional_block(X, f=3, filters=[256, 256, 1024], s=2) # layer 24, 25, 26\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 27, 28, 29\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 30, 31, 32\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 33, 34, 35\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 36, 37, 38\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "\n",
        "\n",
        "    # Stage 5\n",
        "    X = self.convolutional_block(X, f=3, filters=[512, 512, 2048], s=2) # layer 42, 43, 44 \n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 45, 46, 47\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 48, 49, 50\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 48, 49, 50\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 48, 49, 50\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 48, 49, 50\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 48, 49, 50\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 48, 49, 50\n",
        "    # X.shape = (7, 7, 2048)\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X) \n",
        "    # X.shape = (3, 3, 2048)\n",
        "    # X.shape = (3, 3, 2048)\n",
        "\n",
        "    ################CODE END HERE################\n",
        "\n",
        "    # Output layer\n",
        "    X = Flatten()(X) # 2D or 3D image to 1D vector \n",
        "    # X.shape = (None, 18432)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X) \n",
        "    # X.shape = (None, 2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet101')\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  def runResnet152(self, input_shape=(224, 224, 3), classes = 2):\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # ZeroPadding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # X.shape = (230, 230, 3)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2))(X) # layer 1\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X) # layer 2\n",
        "    \n",
        "    # X.shape = (55, 55, 3)\n",
        "\n",
        "    # Stage 2\n",
        "    X = self.convolutional_block(X, f=3, filters=[64, 64, 256], s=1) # layer 3, 4, 5 \n",
        "    # X.shape = (55, 55, 256)\n",
        "    X = self.identity_layer(X, f=3, filters=[64, 64, 256]) # layer 6, 7, 8\n",
        "    X = self.identity_layer(X, f=3, filters=[64, 64, 256]) # layer 9, 10, 11\n",
        "    # X.shape = (55, 55, 256)\n",
        "    \n",
        "\n",
        "    # Stage 3\n",
        "    X = self.convolutional_block(X, f=3, filters=[128, 128, 512], s=2) # layer 12, 13, 14\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 15, 16, 17\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 18, 19, 20\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 21, 22, 23\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 24, 25, 26\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 27, 28, 29\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 30, 31, 32\n",
        "    # X.shape = (25, 28, 512)\n",
        "    X = self.identity_layer(X, f=3, filters=[128, 128, 512]) # layer 33, 34, 35\n",
        "    # X.shape = (25, 28, 512)\n",
        "    \n",
        "\n",
        "    # Stage 4\n",
        "    X = self.convolutional_block(X, f=3, filters=[256, 256, 1024], s=2) # layer 36, 37, 38\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 30, 31, 32\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 33, 34, 35\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 36, 37, 38\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    X = self.identity_layer(X, f=3, filters=[256, 256, 1024]) # layer 39, 40, 41\n",
        "    # X.shape = (14, 14, 1024)\n",
        "    \n",
        "\n",
        "\n",
        "    # Stage 5\n",
        "    X = self.convolutional_block(X, f=3, filters=[512, 512, 2048], s=2) # layer 42, 43, 44 \n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 45, 46, 47\n",
        "    # X.shape = (7, 7, 2048)\n",
        "    X = self.identity_layer(X, f=3, filters=[512, 512, 2048]) # layer 48, 49, 50\n",
        "    # X.shape = (7, 7, 2048)\n",
        "\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X) \n",
        "    # X.shape = (3, 3, 2048)\n",
        "    # X.shape = (3, 3, 2048)\n",
        "\n",
        "    ################CODE END HERE################\n",
        "\n",
        "    # Output layer\n",
        "    X = Flatten()(X) # 2D or 3D image to 1D vector \n",
        "    # X.shape = (None, 18432)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X) \n",
        "    # X.shape = (None, 2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet152')\n",
        "    \n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu0RzP83LPi4"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK0gGZF36BmV"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.python.keras.callbacks import TensorBoard\n",
        "# import tensorflow as tf\n",
        "# from time import time\n",
        "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M7_64xheb7M"
      },
      "outputs": [],
      "source": [
        "filepath = 'gdrive/My Drive/Cloud Research/dataset/Training Models/resnet34/resnet34_ckpt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbVbnjP6eQfg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(filepath)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1ZMWPCRlIh3"
      },
      "outputs": [],
      "source": [
        "acc_thresh = 0.99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqH_0tjE2kMC"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > acc_thresh):   \n",
        "          print(\"\\nWe have reached %2.2f%% accuracy, so we will stopping training.\" %(acc_thresh*100))   \n",
        "          self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpM-mrLu2lXh"
      },
      "outputs": [],
      "source": [
        "callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mountGDrive()"
      ],
      "metadata": {
        "id": "BRrw4Q2oxUDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzipFiles()\n",
        "unzipTrainData()\n",
        "train_df = pd.read_csv('/content/gdrive/MyDrive/Cloud Research__/train_test_df/train.csv')\n"
      ],
      "metadata": {
        "id": "mTT7XiB6zY7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wn3ZQWPCG9l"
      },
      "outputs": [],
      "source": [
        "path = 'train'\n",
        "mountGDrive()\n",
        "unzipFiles()\n",
        "unzipTrainData()\n",
        "# commonList = createCommonList(path)\n",
        "# commonList\n",
        "# final_train_list = createFinalList(commonList, path)\n",
        "# final_train_list\n",
        "# final_test_list, final_train_list = splitData(final_train_list)\n",
        "# train_df = createDataFrame(final_train_list)\n",
        "# train_df.head()\n",
        "# test_df = createDataFrame(final_test_list)\n",
        "# test_df.head()\n",
        "train_df = pd.read_csv('/content/gdrive/MyDrive/Cloud Research__/train_test_df/train.csv')\n",
        "test_df = pd.read_csv('/content/gdrive/MyDrive/Cloud Research__/train_test_df/test.csv')\n",
        "train_df.head()\n",
        "# plotAnyImage(train_df, 805)\n",
        "plotAnyImage(test_df, 805)\n",
        "# generalInfoAboutDAtaFrame(train_df)\n",
        "# generalInfoAboutDAtaFrame(test_df)\n",
        "images, labels = imagesAndLabelsFormater(train_df)\n",
        "# images_test, labels_test = imagesAndLabelsFormater(test_df)\n",
        "images = convertIntoArray(images)\n",
        "# images_test = convertIntoArray(images_test)\n",
        "# Y = custom_data_label_encoder(labels)\n",
        "# Y_test = custom_data_label_encoder(labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8wem5prLNIIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBdVv6XuNwUC"
      },
      "outputs": [],
      "source": [
        "train_df.image[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmGDrHMWRsI7"
      },
      "outputs": [],
      "source": [
        "resnet1 = RESNET34()\n",
        "model34 = resnet1.runResnet34()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSh6aOx4bxCy"
      },
      "outputs": [],
      "source": [
        "# resnet = RESNET()\n",
        "# # model = resnet.runResnet50()\n",
        "# model101 = resnet.runResnet101()\n",
        "# model152 = resnet.runResnet152()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F82F8UONS95G"
      },
      "outputs": [],
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mpEktLiGgvsY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkRvaOrRb6_a"
      },
      "outputs": [],
      "source": [
        "model34.compile(optimizer='adam', \n",
        "                loss='categorical_crossentropy', \n",
        "                metrics=['accuracy'])\n",
        "history34 = model34.fit(images, Y, epochs=100, batch_size=10,\n",
        "                        validation_data=[images_test, Y_test], \n",
        "                        callbacks=[callbacks, cp_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oc5IsJWmguos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = os.path.dirname(filepath)\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(latest)"
      ],
      "metadata": {
        "id": "37_9aMlXEJOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model34.load_weights(latest)"
      ],
      "metadata": {
        "id": "tQK5OJwTEJ1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model152.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iQE5D3HZEMth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkkDFuSnfgjU"
      },
      "outputs": [],
      "source": [
        "# model34.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KHOyzg02ptZ"
      },
      "outputs": [],
      "source": [
        "# print(f'Images shape: {images.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h46EQCDP3rIA"
      },
      "outputs": [],
      "source": [
        "# print(f'Labels shape: {Y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BB-hZ265_qH"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model(model3, 'gdrive/My Drive/Cloud Research/model images/resnet152.png',show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxZ2jFiUEc2u"
      },
      "outputs": [],
      "source": [
        "# images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7qA2keUEeAm"
      },
      "outputs": [],
      "source": [
        "test_df.head()\n",
        "# Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSq5_8fR7EkK"
      },
      "outputs": [],
      "source": [
        "# images_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgMAP1mK7GKR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atUEHNBMfjpw"
      },
      "outputs": [],
      "source": [
        "history34 = model34.fit(images, Y, epochs=100, batch_size=10,validation_data=[images_test, Y_test], callbacks=[callbacks, cp_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history34 = model34.fit(images, Y, epochs=100, batch_size=10,validation_data=[images_test, Y_test], callbacks=[callbacks, cp_callback], initial_epoch= 17)"
      ],
      "metadata": {
        "id": "rt2IKPrNpAGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history34 = model34.fit(images, Y, epochs=100, batch_size=10,validation_data=[images_test, Y_test], callbacks=[callbacks, cp_callback], initial_epoch= 31)"
      ],
      "metadata": {
        "id": "6Ml_d86VTvl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DvRsMFNyuUz"
      },
      "outputs": [],
      "source": [
        "model34.save('/content/gdrive/MyDrive/Cloud Research/model/Training Models/resnet34/dog_cat_resnet101_after_spilt.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muL35SM-FxwH"
      },
      "outputs": [],
      "source": [
        "history34.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CleQHhNGFqXY"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history34.history['accuracy'])\n",
        "plt.plot(history34.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist34_df = pd.DataFrame(history34.history)\n",
        "hist34_df"
      ],
      "metadata": {
        "id": "_DSpi6I48lSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist34_df.to_csv(\"/content/gdrive/MyDrive/Cloud Research/dataset/Training Models/resnet34/history/dog_cat_resnet34_after_spilt.csv\")"
      ],
      "metadata": {
        "id": "6YrEwaYE81xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwidBE3FF4pv"
      },
      "outputs": [],
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history34.history['loss'])\n",
        "plt.plot(history34.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiM7jU980OU1"
      },
      "outputs": [],
      "source": [
        "# !tensorboard --logdir=logs --load_fast=true --bind_all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist101_df = pd.DataFrame(history34.history)\n",
        "hist101_df"
      ],
      "metadata": {
        "id": "8NxZmqYUE7DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"gdrive/MyDrive/\")"
      ],
      "metadata": {
        "id": "bNlMSh_He8ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist101_df = pd.read_csv(\"/content/gdrive/MyDrive/Cloud Research__/dataset/Training Models/resnet101/history/dog_cat_resnet101_after_spilt.csv\")\n",
        "hist152_df = pd.read_csv(\"/content/gdrive/MyDrive/Cloud Research__/dataset/Training Models/resnet152/history/dog_cat_resnet152_after_spilt.csv\")\n",
        "hist34_df = pd.read_csv(\"/content/gdrive/MyDrive/Cloud Research__/dataset/Training Models/resnet34/history/dog_cat_resnet34_after_spilt.csv\")\n",
        "hist_50_df = pd.read_csv(\"/content/gdrive/MyDrive/Cloud Research__/dataset/Training Models/resnet50/history/dog_cat_resnet50_after_spilt.csv\")"
      ],
      "metadata": {
        "id": "IRJZfkC6pEcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist101_df.head()"
      ],
      "metadata": {
        "id": "uagb8zvsixYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.concat([hist152_df.val_accuracy, hist101_df.val_accuracy, hist_50_df.val_accuracy, hist34_df.val_accuracy], axis=1, ignore_index=True)"
      ],
      "metadata": {
        "id": "7lp0dzN5hT4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.columns = [\"hist152_accu\", \"hist101_accu\", \"hist50_accu\", \"hist34_accu\"]"
      ],
      "metadata": {
        "id": "8PNyI8ECiC6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = pd.concat([hist152_df.val_loss, hist101_df.val_loss, hist_50_df.val_loss, hist34_df.val_loss], axis=1, ignore_index=True)"
      ],
      "metadata": {
        "id": "N97QPd9XjcT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1.columns = [\"hist152_loss\", \"hist101_loss\", \"hist50_loss\", \"hist34_loss\"]"
      ],
      "metadata": {
        "id": "KNKX83KDfyGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_comb_accu_df = pd.DataFrame([hist152_df.accuracy, hist101_df.accuracy, hist_50_df.accuracy, hist34_df.accuracy ], columns=[\"152\", \"101\", \"50\", \"34\"])"
      ],
      "metadata": {
        "id": "pRPEeD72fkh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.columns"
      ],
      "metadata": {
        "id": "K7GQ1ukOgGnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(result,y=['hist152_accu', 'hist101_accu', 'hist50_accu', 'hist34_accu'])\n",
        "fig.update_layout(\n",
        "            title={\n",
        "            'text' : \"All Accuracy\",\n",
        "            'x':0.5,\n",
        "            'xanchor': 'center'\n",
        "        })\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "fhnblbzfFBPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(result1,y=['hist152_loss', 'hist101_loss', 'hist50_loss', 'hist34_loss'])\n",
        "fig.update_layout(\n",
        "            title={\n",
        "            'text' : \"All Loss\",\n",
        "            'x':0.5,\n",
        "            'xanchor': 'center'\n",
        "        })\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2WFmtZDYkImG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6oU0MmsnpKoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "hist34_df = pd.read_csv('/content/drive/MyDrive/Cloud Research/model/history/dog_cat_resnet34_after_spilt.csv')"
      ],
      "metadata": {
        "id": "Hk9sJeFesKT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(hist34_df,y=[\"accuracy\",'val_accuracy','loss','val_loss'])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Zux-Qc3HsB51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(hist34_df,y=[\"accuracy\",'val_accuracy'])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wdmaQrJYsB2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(hist34_df,y=['loss','val_loss'])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "RR8uBPVYwUGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jHV__MFeK6ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwjYHBtMK6Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2a6DHppK6TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnkJ4d-kK6Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI_MPM3BK4Rn"
      },
      "outputs": [],
      "source": [
        "# test_path = 'test1'\n",
        "# unzipTestData()\n",
        "# commonTestList = createCommonList(test_path)\n",
        "# final_test_list = createFinalList(commonTestList, test_path)\n",
        "# test_df = createDataFrame(final_test_list)\n",
        "# plotAnyImage(test_df, 5)\n",
        "# generalInfoAboutDAtaFrame(test_df)\n",
        "# test_data, test_labels = imagesAndLabelsFormater(test_df)\n",
        "# test_data = convertIntoArray(test_data)\n",
        "# test_labels = custom_data_label_encoder(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toyv3mq_hK9G"
      },
      "outputs": [],
      "source": [
        "# test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0kAagLohNYA"
      },
      "outputs": [],
      "source": [
        "# test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content/gdrive/MyDrive/Cloud Research__/model/Training Models/resnet152\")"
      ],
      "metadata": {
        "id": "H5izuKJ2iEzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYibdoXYTMHX"
      },
      "outputs": [],
      "source": [
        "old_model = load_model('/content/gdrive/MyDrive/Cloud Research__/model/new_dog_cat_resnet152_after_spilt.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = old_model.evaluate(images_test, Y_test, verbose=2)\n",
        "print(\"Trained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "id": "IUMxSJTh4w4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_model.summary()"
      ],
      "metadata": {
        "id": "05wWq8pXinCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnbHpik4jEpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BZZApq1JjEk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kn2OxbfrjEjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJsjAUbfjEhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BhJ9yQoUjEfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotAnyImage(train_df, 10)"
      ],
      "metadata": {
        "id": "mIepEIdtix7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "  \n",
        "# Pre-processing the image\n",
        "img = tf.keras.utils.load_img(train_df.image[10], target_size = (224, 224))\n",
        "img_tensor = tf.keras.utils.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis = 0)\n",
        "img_tensor = img_tensor / 255.\n",
        "  \n",
        "# Print image tensor shape\n",
        "print(img_tensor.shape)\n",
        "  \n",
        "# Print image\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D8SXInRVi8oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "# Outputs of the 8 layers, which include conv2D and max pooling layers\n",
        "layer_outputs = [layer.output for layer in old_model.layers]\n",
        "activation_model = Model(inputs = old_model.input, outputs = layer_outputs)\n",
        "activations = activation_model.predict(img_tensor)"
      ],
      "metadata": {
        "id": "2GBIZO0Fi8j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(activations)"
      ],
      "metadata": {
        "id": "uEfc_1ysqHOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Activations of first layer\n",
        "first_layer_activation = activations[4]\n",
        "  \n",
        "# shape of first layer activation\n",
        "print(first_layer_activation.shape)\n",
        "  \n",
        "# 2nd channel of the image after first layer of convolution is applied\n",
        "plt.matshow(first_layer_activation[0, :, :, 6], cmap ='viridis')\n",
        "  \n",
        "# 15th channel of the image after first layer of convolution is applied\n",
        "plt.matshow(first_layer_activation[0, :, :, 60], cmap ='viridis')"
      ],
      "metadata": {
        "id": "GfeDNWXDi8h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names = []\n",
        "  \n",
        "for layer in old_model.layers[:139]:\n",
        "  layer_names.append(layer.name)\n",
        "print(layer_names)"
      ],
      "metadata": {
        "id": "dLQPfnKYi8gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path=train_df.image[10] #dog\n",
        "# Define a new Model, Input= image \n",
        "# Output= intermediate representations for all layers in the  \n",
        "# previous model after the first.\n",
        "successive_outputs = [layer.output for layer in old_model.layers]\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = old_model.input, outputs = successive_outputs)\n",
        "#Load the input image\n",
        "img = tf.keras.utils.load_img(img_path, target_size=(224, 224))\n",
        "# Convert ht image to Array of dimension (150,150,3)\n",
        "x   = tf.keras.utils.img_to_array(img)                           \n",
        "x   = x.reshape((1,) + x.shape)\n",
        "# Rescale by 1/255\n",
        "x /= 255.0\n",
        "# Let's run input image through our vislauization network\n",
        "# to obtain all intermediate representations for the image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "# Retrieve are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in old_model.layers]\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  print(feature_map.shape)\n",
        "  if len(feature_map.shape) == 4 and layer_name.split(\"_\")[0] == 'conv2d':\n",
        "    \n",
        "    # Plot Feature maps for the conv / maxpool layers, not the fully-connected layers\n",
        "   \n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    if n_features > 8:\n",
        "      n_features = 8\n",
        "    # n_features = 3\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "    \n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    \n",
        "    # Postprocess the feature to be visually palatable\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      # Tile each filter into a horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "# Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='viridis' )"
      ],
      "metadata": {
        "id": "BqAlQxizi8ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.layers.Conv2D"
      ],
      "metadata": {
        "id": "7fzMRTX0s_td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# old_model.layers[6].name.split('_')[0]"
      ],
      "metadata": {
        "id": "19TroXdfskEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Conv2d"
      ],
      "metadata": {
        "id": "JtL5WuxdsgWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ###########################################################################################################\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torchvision\n",
        "# from torchvision import models, transforms, utils\n",
        "# from torch.autograd import Variable\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import scipy.misc\n",
        "# from PIL import Image\n",
        "# import json\n",
        "# %matplotlib inline\n",
        "# # we will save the conv layer weights in this list\n",
        "# model_weights =[]\n",
        "# #we will save the 49 conv layers in this list\n",
        "# conv_layers = []\n",
        "# # get all the model children as list\n",
        "# model_children = list(old_model.layers)\n",
        "# #counter to keep count of the conv layers\n",
        "# counter = 0\n",
        "# #append all the conv layers and their respective wights to the list\n",
        "# for i in range(len(model_children)):\n",
        "#     if model_children[i].name == 'conv2d' or model_children[i].name.split('_')[0] == 'conv2d':\n",
        "#         counter+=1\n",
        "#         model_weights.append(model_children[i].get_weights())\n",
        "#         conv_layers.append(model_children[i])\n",
        "#     # elif type(model_children[i]) == nn.Sequential:\n",
        "#     #     for j in range(len(model_children[i])):\n",
        "#     #         for child in model_children[i][j].children():\n",
        "#     #             if type(child) == nn.Conv2d:\n",
        "#     #                 counter+=1\n",
        "#     #                 model_weights.append(child.weight)\n",
        "#     #                 conv_layers.append(child)\n",
        "# print(f\"Total convolution layers: {counter}\")\n",
        "# print(\"conv_layers\")"
      ],
      "metadata": {
        "id": "-o1LSXAei8Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=0., std=1.)\n",
        "# ])"
      ],
      "metadata": {
        "id": "FjCYADiuIWZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image = Image.open(train_df.image[10])\n",
        "# plt.imshow(image)"
      ],
      "metadata": {
        "id": "outthjlWIZ3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# image = transform(image)\n",
        "# print(f\"Image shape before: {image.shape}\")\n",
        "# image = image.unsqueeze(0)\n",
        "# print(f\"Image shape after: {image.shape}\")\n",
        "# image = image.to(device)"
      ],
      "metadata": {
        "id": "Md-gd7CcHTRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conv_layers[0](image)"
      ],
      "metadata": {
        "id": "u0ZnkHA2I5qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outputs = []\n",
        "# names = []\n",
        "# successive_outputs = [layer.output for layer in old_model.layers]\n",
        "# #visualization_model = Model(img_input, successive_outputs)\n",
        "# visualization_model = tf.keras.models.Model(inputs = old_model.input, outputs = successive_outputs)\n",
        "# #Load the input image\n",
        "# img = tf.keras.utils.load_img(img_path, target_size=(224, 224))\n",
        "# # Convert ht image to Array of dimension (150,150,3)\n",
        "# x   = tf.keras.utils.img_to_array(img)                           \n",
        "# x   = x.reshape((1,) + x.shape)\n",
        "# # Rescale by 1/255\n",
        "# x /= 255.0\n",
        "# # Let's run input image through our vislauization network\n",
        "# # to obtain all intermediate representations for the image.\n",
        "# successive_feature_maps = visualization_model.predict(x)\n",
        "# # Retrieve are the names of the layers, so can have them as part of our plot\n",
        "# layer_names = [layer.name for layer in old_model.layers]\n",
        "# for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "#   if layer_name.split(\"_\")[0] == \"conv2d\":\n",
        "# #   if layer_name == 'conv2d' or layer_name.split(\"-\")[0] == 'conv2d':\n",
        "#     outputs.append(feature_map)\n",
        "#     names.append(layer_name)\n",
        "# for feature_map in outputs:\n",
        "#     print(feature_map.shape)"
      ],
      "metadata": {
        "id": "Foom5rPkHTOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ToVx8B1xQa75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# processed = []\n",
        "# for feature_map in outputs:\n",
        "#     feature_map = feature_map.squeeze(0)\n",
        "#     gray_scale = tf.math.reduce_sum(feature_map,0)\n",
        "#     gray_scale = gray_scale / feature_map.shape[0]\n",
        "#     processed.append(gray_scale.numpy())\n",
        "# for fm in processed:\n",
        "#     print(fm.shape)"
      ],
      "metadata": {
        "id": "exDGZLUwHTHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = plt.figure(figsize=(30, 50))\n",
        "# for i in range(len(processed)):\n",
        "#     if i+1 < 20:\n",
        "#       a = fig.add_subplot(5, 4, i+1)\n",
        "#       imgplot = plt.imshow(processed[i])\n",
        "#       a.axis(\"off\")\n",
        "#       a.set_title(names[i].split('(')[0], fontsize=30)\n",
        "# plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')"
      ],
      "metadata": {
        "id": "4NJjXQJOHTEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOG6PIl17Dua"
      },
      "outputs": [],
      "source": [
        "def predict_the_score(path):\n",
        "  # img = image.load_img(path, target_size=(224,224))\n",
        "  # img2 = image.img_to_array(img)\n",
        "  img2 = np.expand_dims(path, axis=0)\n",
        "  img2 = preprocess_input(img2)\n",
        "  ans = old_model101.predict(img2)\n",
        "  return np.round(ans)\n",
        "  # return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cxes_xyglC1"
      },
      "outputs": [],
      "source": [
        "Y[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SibF9kVFMx14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdnQiH2Ugit5"
      },
      "outputs": [],
      "source": [
        "predict_the_score(images_test[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvG87Xx_7Z0A"
      },
      "outputs": [],
      "source": [
        "# test_ans = []\n",
        "# for n, i in enumerate(final_test_list):\n",
        "#   print(f\"[INFO] Image number {n} started.\")\n",
        "#   label = i[0]\n",
        "#   prediction = predict_the_score(i[1])\n",
        "#   test_ans.append((label, prediction))\n",
        "# print(f\"[DONE] Prediction completed\\nTotal images predicted: {len(test_ans)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROPAaR1Qg5S4"
      },
      "outputs": [],
      "source": [
        "test_ans = []\n",
        "for i in range(len(images_valid)):\n",
        "  print(f\"[INFO] Image number {i} started.\")\n",
        "  label = labels_valid[i]\n",
        "  prediction = predict_the_score(images_valid[i])\n",
        "  test_ans.append((label, prediction))\n",
        "print(f\"[DONE] Prediction completed\")\n",
        "print(\"Total images predicted: {len(test_ans)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5Aqmayuelil"
      },
      "outputs": [],
      "source": [
        "# predict_the_score(final_test_list[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWn-0io_en1f"
      },
      "outputs": [],
      "source": [
        "Y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGvGEbqBeXHL"
      },
      "outputs": [],
      "source": [
        "test_ans[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0qmOC70efRr"
      },
      "outputs": [],
      "source": [
        "test_ans[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlZtPOtFl6K0"
      },
      "outputs": [],
      "source": [
        "'Dog' if test_ans[0][0][0] else 'Cat'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_ans)"
      ],
      "metadata": {
        "id": "x8-LkimNX1QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_list = test_df['image']"
      ],
      "metadata": {
        "id": "axfaVf2R1WBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_list[0]"
      ],
      "metadata": {
        "id": "uOCPz58OX4Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VJLbSCYA7PP"
      },
      "outputs": [],
      "source": [
        "final_test_ans = []\n",
        "for i in range(len(test_ans)):\n",
        "  if(test_ans[i][1][0][0]):\n",
        "    final_test_ans.append((f'{final_test_list[i]}', 'cat', test_ans[i][0]))\n",
        "  else:\n",
        "    print(i)\n",
        "    final_test_ans.append((f'{final_test_list[i]}', 'dog', test_ans[i][0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ7IIoZ8Cktr"
      },
      "outputs": [],
      "source": [
        "final_test_df = pd.DataFrame(final_test_ans, columns=['index', 'prediction', 'actual'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPjeMlhOCuCo"
      },
      "outputs": [],
      "source": [
        "final_test_df = final_test_df.sort_values(by='index', ascending=True)\n",
        "final_test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFFQzkNFfQeL"
      },
      "outputs": [],
      "source": [
        "plt.imshow(mpimg.imread('train/cat.10007.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVz65ZUTC1Ed"
      },
      "outputs": [],
      "source": [
        "final_test_df.to_csv('gdrive/My Drive/Cloud Research/Test DF/resnet101/final_test_df_101.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_06aojmGFwv"
      },
      "outputs": [],
      "source": [
        "final_test_ans[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new list of top 9 images\n",
        "\n"
      ],
      "metadata": {
        "id": "czegjDO0yVbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgWFlBYQF86J"
      },
      "outputs": [],
      "source": [
        "# Importing the PIL library\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "\n",
        "\n",
        "# for i in range(len(final_test_ans)):\n",
        "#   print(f\"[INFO] Processing image number {i}\")\n",
        "#   # Open an Image\n",
        "#   img = Image.open(final_test_ans[i][0])\n",
        "\n",
        "#   # Call draw Method to add 2D graphics in an image\n",
        "#   I1 = ImageDraw.Draw(img)\n",
        "\n",
        "#   myFont = ImageFont.truetype('Montserrat-Bold.ttf', 30)\n",
        "\n",
        "\n",
        "#   # Add Text to an image\n",
        "#   I1.text((10, 10), final_test_ans[i][1], font = myFont, fill=(255, 0, 0),)\n",
        "\n",
        "#   # Display edited image\n",
        "#   img.show()\n",
        "\n",
        "#   save_path = f\"Resnet34/{final_test_ans[i][0]}\"\n",
        "#   # Save the edited image\n",
        "#   img.save(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWYPvZkxRfsH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "len(os.listdir(\"Resnet50/test1\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNqZeg-hR_fz"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/testImages.zip /content/Resnet50/test1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPfBltyXSSdc"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/testImages.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84zFC4HZ8GDv"
      },
      "outputs": [],
      "source": [
        "plt.imshow(mpimg.imread(final_test_ans[5][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQCBGPMB8Nuy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whYWOpwsM5wB"
      },
      "outputs": [],
      "source": [
        "# img = image.load_img(final_train_list[4][1], target_size=(224,224))\n",
        "# img2 = image.img_to_array(img)\n",
        "# img2 = np.expand_dims(img2, axis=0)\n",
        "# img2 = preprocess_input(img2)\n",
        "\n",
        "# plt.imshow(mpimg.imread(final_train_list[4][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BKiQ5_ULebm"
      },
      "outputs": [],
      "source": [
        "# test_image = np.array(img2)\n",
        "# model.predict(test_image)\n",
        "# img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_t_nNMtMLRU"
      },
      "outputs": [],
      "source": [
        "# ans = model.predict(img2)\n",
        "# np.round(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quoFSJL8NZN3"
      },
      "outputs": [],
      "source": [
        "# 9.9999988e-01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUSEKTC1PVJK"
      },
      "outputs": [],
      "source": [
        "# np.around(1.4127232e-07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp7d5r3Jb8BH"
      },
      "outputs": [],
      "source": [
        "# model = Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVN96RObPW0Z"
      },
      "outputs": [],
      "source": [
        "# get_acc = old_model.history['accuracy']\n",
        "# value_acc = old_model.history['val_accuracy']\n",
        "# get_loss = old_model.history['loss']\n",
        "# validation_loss = old_model.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuVp7RAcf6Kk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmzrro1oe6lB"
      },
      "outputs": [],
      "source": [
        "# img = image.load_img('train/cat.1.jpg', target_size=(224,224))\n",
        "# img2 = image.img_to_array(img)\n",
        "# img2 = np.expand_dims(img2, axis=0)\n",
        "# img2 = preprocess_input(img2)\n",
        "\n",
        "# plt.imshow(mpimg.imread('train/cat.1.jpg'))\n",
        "# ans = model.predict(img2)\n",
        "# np.around(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7px-ybAftui"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_e_u9mW7MWq"
      },
      "outputs": [],
      "source": [
        "# test_path = 'test1'\n",
        "# train_path = 'train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFN9AZMyhqeb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "OGOBw5g05YfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "NiiuSOnK9r3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "print(\"[INFO] Mounting google drive to this notebook.\")\n",
        "drive.mount('/content/gdrive')\n",
        "print(\"\\n-------------------------------\\n[DONE] G-Drive Mount Successful\\n-------------------------------\")"
      ],
      "metadata": {
        "id": "zWpAdn7t81XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Unzipping the dataset from google drive.\")\n",
        "%time !unzip -q gdrive/My\\ Drive/Cloud\\ Research/dataset/data.zip\n",
        "print(\"-------------------------------\\n[DONE] Unzip Successful\\n-------------------------------\")\n"
      ],
      "metadata": {
        "id": "3AWe37LDBsF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[INFO] Unzipping Training Data\")\n",
        "%time !unzip -q train.zip\n",
        "print(\"-------------------------------\\n[DONE] Unzipping Training Data Successful\\n-------------------------------\")\n"
      ],
      "metadata": {
        "id": "XSrkWtxkBgVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "# from IPython.display import svg\n",
        "from keras.utils.vis_utils import model_to_dot, plot_model\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n"
      ],
      "metadata": {
        "id": "PjQUDIuemHRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/gdrive/MyDrive/Cloud Research/train_test_df/test.csv')\n",
        "# plotAnyImage(test_df, 805)\n",
        "# generalInfoAboutDAtaFrame(test_df)\n",
        "images_test, labels_test = imagesAndLabelsFormater(test_df)\n",
        "images_test = convertIntoArray(images_test)\n",
        "Y_test = custom_data_label_encoder(labels_test)"
      ],
      "metadata": {
        "id": "Y_HO6n85mWXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet 34"
      ],
      "metadata": {
        "id": "aP4AEfiNj8je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "old_model34 = load_model('/content/gdrive/MyDrive/Cloud Research/model/Training Models/resnet34/dog_cat_resnet34_after_spilt.h5')"
      ],
      "metadata": {
        "id": "toJQo1PaAqz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFksnRu00S42"
      },
      "outputs": [],
      "source": [
        "loss, acc = old_model34.evaluate(images_test, Y_test, verbose=2)\n",
        "print(\"Trained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfFilePath = '/content/gdrive/MyDrive/Cloud Research__/Test DF/resnet34/final_test_df_34.csv'"
      ],
      "metadata": {
        "id": "_eN7jdO25fCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df34 = pd.read_csv(dfFilePath)"
      ],
      "metadata": {
        "id": "rBYANufp8s9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df34.columns = ['index', 'filePath', 'prediction', 'actual']"
      ],
      "metadata": {
        "id": "vZgfiET2Ahtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df34.head()"
      ],
      "metadata": {
        "id": "5zk0g7du8xBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZK7BLxUBLRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adpc = []\n",
        "acpd = []\n",
        "acpc = []\n",
        "adpd = []\n",
        "for i in range(len(df34)):\n",
        "  if df34.prediction[i] != df34.actual[i]:\n",
        "    if df34.actual[i] == 'dog':\n",
        "      adpc.append(df34.filePath[i])\n",
        "    else:\n",
        "      acpd.append(df34.filePath[i])\n",
        "  elif df34.prediction[i] == df34.actual[i]:\n",
        "    if df34.actual[i] == 'dog':\n",
        "      adpd.append(df34.filePath[i])\n",
        "    else:\n",
        "      acpc.append(df34.filePath[i])\n",
        "print(f'Actual cat but predicted dog: {len(acpd)}\\nActual dog but predicted cat: {len(adpc)}\\nActual dog but predicted dog: {len(adpd)}\\nActual cat but predicted cat: {len(acpc)}\\nTotal count: {len(df34)}')"
      ],
      "metadata": {
        "id": "Gkm171XQ93jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acpd[:10][0]"
      ],
      "metadata": {
        "id": "R7agPoXg_CxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adpc[0]"
      ],
      "metadata": {
        "id": "kKTpD4H6_W8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def plotImage(path):\n",
        "  plt.imshow(mpimg.imread(path))"
      ],
      "metadata": {
        "id": "zipaCZ8D_0TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix as cm\n",
        "import seaborn as sns\n",
        "\n",
        "cm_matrix = cm(df34.actual, df34.prediction, labels=['cat', 'dog'])\n",
        "\n",
        "ax = sns.heatmap(cm_matrix, annot=True, fmt='0.0f', cmap='Blues')\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['cat', 'dog']); ax.yaxis.set_ticklabels(['cat', 'dog']);\n",
        "plt.title('ResNet 34 ')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gbgZa50aCz7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "spnW8K3aNNxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('DataSet')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, images[200:300]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    # ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yjW0DstyLwVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('Actual Dog predicted Cat')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, adpc[:10]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OkS0MOGUuXZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('Actual Cat predicted Dog')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, acpd[:10]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GT_MMkH9uXU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGd9Ox-ZuW4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 50\n"
      ],
      "metadata": {
        "id": "0ghv97rvkCe9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0LZd9xDBRjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_model50 = load_model('/content/gdrive/MyDrive/Cloud Research/model/Training Models/resnet50/dog_cat_resnet50_after_spilt.h5')"
      ],
      "metadata": {
        "id": "SX0NkFWABRzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abPQaq3QBRzG"
      },
      "outputs": [],
      "source": [
        "loss, acc = old_model50.evaluate(images_test, Y_test, verbose=2)\n",
        "print(\"Trained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfFilePath = '/content/gdrive/MyDrive/Cloud Research__/Test DF/resnet50/final_test_df_50.csv'"
      ],
      "metadata": {
        "id": "dEcVZ6MfBRzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df50 = pd.read_csv(dfFilePath)"
      ],
      "metadata": {
        "id": "IZACNWvRBRzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df50.columns = ['index', 'filePath', 'prediction', 'actual']"
      ],
      "metadata": {
        "id": "VZ_qp55rBRzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df50.head()"
      ],
      "metadata": {
        "id": "Coq6q6wkBRzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81Bq9Fy9BRzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adpc = []\n",
        "acpd = []\n",
        "acpc = []\n",
        "adpd = []\n",
        "for i in range(len(df50)):\n",
        "  if df50.prediction[i] != df50.actual[i]:\n",
        "    if df50.actual[i] == 'dog':\n",
        "      adpc.append(df50.filePath[i])\n",
        "    else:\n",
        "      acpd.append(df50.filePath[i])\n",
        "  elif df50.prediction[i] == df50.actual[i]:\n",
        "    if df50.actual[i] == 'dog':\n",
        "      adpd.append(df50.filePath[i])\n",
        "    else:\n",
        "      acpc.append(df50.filePath[i])\n",
        "print(f'Actual cat but predicted dog: {len(acpd)}\\nActual dog but predicted cat: {len(adpc)}\\nActual dog but predicted dog: {len(adpd)}\\nActual cat but predicted cat: {len(acpc)}\\nTotal count: {len(df50)}')"
      ],
      "metadata": {
        "id": "Cha87jrxBRzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acpd[0]"
      ],
      "metadata": {
        "id": "r1d48DjHBRzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adpc[0]"
      ],
      "metadata": {
        "id": "vRMXOt4HBRzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def plotImage(path):\n",
        "  plt.imshow(mpimg.imread(path))"
      ],
      "metadata": {
        "id": "bxOtTsjBBRzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix as cm\n",
        "import seaborn as sns\n",
        "\n",
        "cm_matrix = cm(df50.actual, df50.prediction, labels=['cat', 'dog'])\n",
        "\n",
        "ax = sns.heatmap(cm_matrix, annot=True, fmt='0.0f', cmap='Blues')\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['cat', 'dog']); ax.yaxis.set_ticklabels(['cat', 'dog']);\n",
        "plt.title('ResNet 50 ')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HIwTbhyRBRzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lUDPrGt0PPMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('Actual Dog predicted Cat')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, adpc[:10]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z288CLuuPPcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('Actual Cat predicted Dog')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, acpd[:10]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZJpSEJ3LPPcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 101"
      ],
      "metadata": {
        "id": "NF6-sx5UkHXB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZKykSuoDBTTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_model101 = load_model('/content/gdrive/MyDrive/Cloud Research/model/Training Models/resnet101/dog_cat_resnet101_after_spilt.h5')"
      ],
      "metadata": {
        "id": "DSjhQnpcBTga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAxTuVxGBTga"
      },
      "outputs": [],
      "source": [
        "loss, acc = old_model101.evaluate(images_test, Y_test, verbose=2)\n",
        "print(\"Trained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfFilePath = '/content/gdrive/MyDrive/Cloud Research__/Test DF/resnet101/final_test_df_101.csv'"
      ],
      "metadata": {
        "id": "RFBPWYIWBTgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df101 = pd.read_csv(dfFilePath)"
      ],
      "metadata": {
        "id": "h3cZBQhNBTgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df101.columns = ['index', 'filePath', 'prediction', 'actual']"
      ],
      "metadata": {
        "id": "FKBHYEtRBTgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df101.head()"
      ],
      "metadata": {
        "id": "CZdIVg1PBTgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8KgoJE6BTgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adpc = []\n",
        "acpd = []\n",
        "acpc = []\n",
        "adpd = []\n",
        "for i in range(len(df101)):\n",
        "  if df101.prediction[i] != df101.actual[i]:\n",
        "    if df101.actual[i] == 'dog':\n",
        "      adpc.append(df101.filePath[i])\n",
        "    else:\n",
        "      acpd.append(df101.filePath[i])\n",
        "  elif df101.prediction[i] == df101.actual[i]:\n",
        "    if df101.actual[i] == 'dog':\n",
        "      adpd.append(df101.filePath[i])\n",
        "    else:\n",
        "      acpc.append(df101.filePath[i])\n",
        "print(f'Actual cat but predicted dog: {len(acpd)}\\nActual dog but predicted cat: {len(adpc)}\\nActual dog but predicted dog: {len(adpd)}\\nActual cat but predicted cat: {len(acpc)}\\nTotal count: {len(df50)}')"
      ],
      "metadata": {
        "id": "4uTOYTYPBTgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acpd[0]"
      ],
      "metadata": {
        "id": "BhSDIE-7BTgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adpc[0]"
      ],
      "metadata": {
        "id": "iH8XhA-lBTgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def plotImage(path):\n",
        "  plt.imshow(mpimg.imread(path))"
      ],
      "metadata": {
        "id": "t2yW90uIBTgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix as cm\n",
        "import seaborn as sns\n",
        "\n",
        "cm_matrix = cm(df101.actual, df101.prediction, labels=['cat', 'dog'])\n",
        "\n",
        "ax = sns.heatmap(cm_matrix, annot=True, fmt='0.0f', cmap='Blues')\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['cat', 'dog']); ax.yaxis.set_ticklabels(['cat', 'dog']);\n",
        "plt.title('ResNet 101 ')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t8XPHUHeBTgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "loSqjTukPSGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('Actual Dog predicted Cat')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, adpc[:10]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-usaYPu9PSV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('Actual Cat predicted Dog')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, acpd[:10]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2WDFGlaPSV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 152"
      ],
      "metadata": {
        "id": "wAYaDJaykMaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "old_model152 = load_model('/content/gdrive/MyDrive/Cloud Research/dog_cat_resnet152_after_spilt_1.h5')"
      ],
      "metadata": {
        "id": "Ofk_EHjQBUlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4uBk566BUlg"
      },
      "outputs": [],
      "source": [
        "loss, acc = old_model152.evaluate(images_test, Y_test, verbose=2)\n",
        "print(\"Trained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfFilePath = '/content/gdrive/MyDrive/Cloud Research__/Test DF/resnet152/final_test_df_152.csv'"
      ],
      "metadata": {
        "id": "4BnP6l78BUlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df152 = pd.read_csv(dfFilePath)"
      ],
      "metadata": {
        "id": "RPS8ZVJ6BUlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df152.columns = ['index', 'filePath', 'prediction', 'actual']"
      ],
      "metadata": {
        "id": "af2QgxupBUlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df152.head()"
      ],
      "metadata": {
        "id": "wh4osJI7BUlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = [i for i in df34.prediction]\n",
        "y_true = [i for i in df34.actual]"
      ],
      "metadata": {
        "id": "aDf9jxQjBUlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[:10]"
      ],
      "metadata": {
        "id": "h7Mt-KYOKiuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "metadata": {
        "id": "Vgq72HCeKSx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision34 = recall_score(y_true, y_pred, average='binary')"
      ],
      "metadata": {
        "id": "jSTRVNj8KSpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adpc = []\n",
        "acpd = []\n",
        "acpc = []\n",
        "adpd = []\n",
        "for i in range(len(df152)):\n",
        "  if df152.prediction[i] != df152.actual[i]:\n",
        "    if df152.actual[i] == 'dog':\n",
        "      adpc.append(df152.filePath[i])\n",
        "    else:\n",
        "      acpd.append(df152.filePath[i])\n",
        "  elif df152.prediction[i] == df152.actual[i]:\n",
        "    if df152.actual[i] == 'dog':\n",
        "      adpd.append(df152.filePath[i])\n",
        "    else:\n",
        "      acpc.append(df152.filePath[i])\n",
        "print(f'Actual cat but predicted dog: {len(acpd)}\\nActual dog but predicted cat: {len(adpc)}\\nActual dog but predicted dog: {len(adpd)}\\nActual cat but predicted cat: {len(acpc)}\\nTotal count: {len(df152)}')"
      ],
      "metadata": {
        "id": "DOp0EX5cBUlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acpd[0]"
      ],
      "metadata": {
        "id": "Q5aNnYsiBUlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adpc[0]"
      ],
      "metadata": {
        "id": "WgU28BsjBUlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def plotImage(path):\n",
        "  plt.imshow(mpimg.imread(path))"
      ],
      "metadata": {
        "id": "Rcyh8Dp1BUlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix as cm\n",
        "import seaborn as sns\n",
        "\n",
        "cm_matrix = cm(df152.actual, df152.prediction, labels=['cat', 'dog'])\n",
        "\n",
        "ax = sns.heatmap(cm_matrix, annot=True, fmt='0.0f', cmap='Blues')\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['cat', 'dog']); ax.yaxis.set_ticklabels(['cat', 'dog']);\n",
        "plt.title('ResNet 152 ')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TNXZtu2BBUlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HApnctcTPTXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('Actual Dog predicted Cat')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, adpc[:10]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZOH8CM50PTh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.title('Actual Cat predicted Dog')\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, acpd[:10]):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(cv2.resize(cv2.imread(im), (224, 224)))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ocFsMCl7PTh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5_ejGzXzbRPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2l452LTVTZIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJj6G-pNTZEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dfFilePath = 'gdrive/My Drive/Cloud Research/final_test_df_152.csv'\n",
        "df34 = pd.read_csv(dfFilePath)\n",
        "\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(df34.actual, df34.prediction)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Cat', 'Dog'])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.title(\"Resnet 152\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q8_HLzPeTZBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist152_df = pd.read_csv('/content/gdrive/MyDrive/Cloud Research/dog_cat_resnet152_after_spilt.csv')"
      ],
      "metadata": {
        "id": "FTg3hWa7TqHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(hist152_df,y=[\"accuracy\",'val_accuracy','loss','val_loss'])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "J9y6Fn7WWJP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "CN2zuaL2WMjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwcJsjtcPdhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFilePath = '/content/gdrive/MyDrive/Cloud Research__/Test DF/resnet34/final_test_df_34.csv'\n",
        "df34 = pd.read_csv(dfFilePath)\n",
        "df34.columns = ['index', 'filePath', 'prediction', 'actual']\n",
        "y_pred34 = [i for i in df34.prediction]\n",
        "y_true34 = [i for i in df34.actual]\n",
        "\n"
      ],
      "metadata": {
        "id": "KPK8V6TYPQOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFilePath = '/content/gdrive/MyDrive/Cloud Research__/Test DF/resnet50/final_test_df_50.csv'\n",
        "df50 = pd.read_csv(dfFilePath)\n",
        "df50.columns = ['index', 'filePath', 'prediction', 'actual']\n",
        "y_pred50 = [i for i in df50.prediction]\n",
        "y_true50 = [i for i in df50.actual]\n",
        "\n"
      ],
      "metadata": {
        "id": "Reur4sbRQDQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfFilePath = '/content/gdrive/MyDrive/Cloud Research__/Test DF/resnet101/final_test_df_101.csv'\n",
        "df101 = pd.read_csv(dfFilePath)\n",
        "df101.columns = ['index', 'filePath', 'prediction', 'actual']\n",
        "y_pred101 = [i for i in df101.prediction]\n",
        "y_true101 = [i for i in df101.actual]\n",
        "\n"
      ],
      "metadata": {
        "id": "wyGJIEaCQDHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"34:\\n\")\n",
        "print(classification_report(y_true34, y_pred34))"
      ],
      "metadata": {
        "id": "j_9O7o5yQC0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"50:\\n\")\n",
        "print(classification_report(y_true50, y_pred50))"
      ],
      "metadata": {
        "id": "bwUJVunrQCrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"101:\\n\")\n",
        "print(classification_report(y_true101, y_pred101))"
      ],
      "metadata": {
        "id": "96sd8CnDQY1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff = []\n",
        "ff.append([0.52, 0.94, 0.67, 5000])\n",
        "ff.append([0.63, 0.94, 0.75, 5000])"
      ],
      "metadata": {
        "id": "3uLscG1VQYxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff"
      ],
      "metadata": {
        "id": "iKgP0mvNQX6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acxm_Gw0EZ2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uP7WrklEY5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yznHAnNRHxIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3AqxMC-DIkVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NaWCnSHdJuwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qbXREkxZQo_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skJRrLTNQo7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EGwExNnSQo43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0cxZyK6KQo2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0z2P_IBtO6u1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}